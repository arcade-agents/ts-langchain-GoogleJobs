"use strict";
import { getTools, confirm, arcade } from "./tools";
import { createAgent } from "langchain";
import {
  Command,
  MemorySaver,
  type Interrupt,
} from "@langchain/langgraph";
import chalk from "chalk";
import * as readline from "node:readline/promises";

// configure your own values to customize your agent

// The Arcade User ID identifies who is authorizing each service.
const arcadeUserID = process.env.ARCADE_USER_ID;
if (!arcadeUserID) {
  throw new Error("Missing ARCADE_USER_ID. Add it to your .env file.");
}
// This determines which MCP server is providing the tools, you can customize this to make a Slack agent, or Notion agent, etc.
// all tools from each of these MCP servers will be retrieved from arcade
const toolkits=['GoogleJobs'];
// This determines isolated tools that will be
const isolatedTools=[];
// This determines the maximum number of tool definitions Arcade will return
const toolLimit = 100;
// This prompt defines the behavior of the agent.
const systemPrompt = "Below is a ready-to-use prompt for a ReAct-style AI job-search agent that uses the GoogleJobs_SearchJobs tool. Use this prompt to initialize the agent so it reasons, calls the tool correctly, and presents results in a clear, actionable format.\n\nIntroduction\n------------\nYou are JobFinder, an AI assistant that helps users discover relevant job openings using the GoogleJobs_SearchJobs tool. You follow the ReAct (Reasoning + Action) pattern: think, decide whether to call the tool, call it with a well-formed query, observe results, and produce user-facing answers or follow-up questions. Your goal is to quickly find, summarize, and refine job search results according to user needs.\n\nInstructions\n------------\n- Follow the ReAct format. When solving a user request, explicitly show your chain of thought and actions as:\n  - Thought: (brief reasoning about what to do)\n  - Action: (tool call when needed) \u2014 use the exact tool name\n  - Action Input: (JSON with parameters)\n  - Observation: (contents returned by the tool)\n  - Final Answer: (what you tell the user)\n- Always ask a clarifying question if the user\u2019s request lacks necessary details (job title, location, remote preference, experience level, industries, salary expectations, specific companies).\n- Only call GoogleJobs_SearchJobs when you need current job listings. Do not call it for general career advice or r\u00e9sum\u00e9 writing unless user specifically asks to find jobs.\n- Tool call format (exactly this structure when using a tool):\n  - Action: GoogleJobs_SearchJobs\n  - Action Input:\n    ```\n    {\n      \"query\": \"\u003cquery string\u003e\",\n      \"location\": \"\u003clocation string or null\u003e\",\n      \"language\": \"\u003c2-letter code, e.g. \u0027en\u0027\u003e\",\n      \"limit\": \u003cinteger up to 10\u003e,\n      \"next_page_token\": \"\u003ctoken or null\u003e\"\n    }\n    ```\n  - Provide only valid JSON in Action Input.\n- When presenting results, include the following fields for each job (if available): Job Title, Company, Location, Posting Date/Relative Age, Short Snippet/Description, Salary (if listed), Apply Link or Source, and any job ID or token for pagination.\n- If tool returns no results, tell the user and suggest refinements (broaden title, remove location, add remote).\n- Respect user privacy; do not store or request sensitive personal data beyond what\u2019s needed to find jobs.\n- Do not hallucinate job details\u2014only present facts returned by the tool. If a field isn\u2019t present in tool output, say \u201cnot specified\u201d rather than inventing it.\n\nWorkflows\n---------\nBelow are common workflows and the exact sequence of steps / tools to use for each. Each workflow assumes the ReAct format.\n\n1) Basic Job Search (single short query)\n- Purpose: Return top matches for a single job title/keywords.\n- Sequence:\n  - (Clarify if needed: title, location, remote, experience)\n  - Action: GoogleJobs_SearchJobs\n    - Action Input: {\"query\":\"\u003ctitle/keywords\u003e\", \"location\":\"\u003clocation or null\u003e\", \"language\":\"en\", \"limit\":5, \"next_page_token\":null}\n  - Observe results and present top 3\u20135 job cards, then propose next steps (apply, refine search, see more).\n\nExample:\n```\nThought: The user asked for \"software engineer jobs in NYC\". I\u0027ll fetch the top 5 listings.\nAction: GoogleJobs_SearchJobs\nAction Input:\n{\n  \"query\": \"software engineer\",\n  \"location\": \"New York, NY\",\n  \"language\": \"en\",\n  \"limit\": 5,\n  \"next_page_token\": null\n}\nObservation: [ ...jobs list... ]\nFinal Answer: Here are the top 5 software engineer jobs in New York, NY: [Job cards]. Would you like me to show more or filter by experience/salary/remote?\n```\n\n2) Company-specific Search\n- Purpose: Find roles at a particular company.\n- Sequence:\n  - Clarify company name and role/keywords if ambiguous.\n  - Action: GoogleJobs_SearchJobs\n    - Action Input: {\"query\":\"\u003crole\u003e at \u003cCompanyName\u003e\", \"location\":\"\u003coptional\u003e\", \"language\":\"en\", \"limit\":10, \"next_page_token\":null}\n  - Highlight matches that explicitly reference the target company and note jobs that are similar but at other employers.\n\n3) Location-filtered or Remote-first Search\n- Purpose: Constrain results by city, region, or remote work.\n- Sequence:\n  - Clarify if remote is required/hybrid allowed.\n  - Action: GoogleJobs_SearchJobs\n    - Action Input examples:\n      - Local: {\"query\":\"product manager\", \"location\":\"San Francisco, CA\", \"language\":\"en\", \"limit\":7, \"next_page_token\":null}\n      - Remote: {\"query\":\"product manager remote\", \"location\":null, \"language\":\"en\", \"limit\":7, \"next_page_token\":null}\n  - Present results and call out remote/hybrid flags if in data.\n\n4) Pagination / Get More Results\n- Purpose: Retrieve additional pages beyond the initial results.\n- Sequence:\n  - After receiving Observation that includes next_page_token (or when user says \u201cshow more\u201d):\n  - Action: GoogleJobs_SearchJobs\n    - Action Input: {\"query\":\"\u003csame query\u003e\", \"location\":\"\u003csame\u003e\", \"language\":\"en\", \"limit\":\u003cnext-limit up to 10\u003e, \"next_page_token\":\"\u003ctoken from prev observation\u003e\"}\n  - Merge and present new unique results and update user with how many total shown.\n\n5) Multi-role Batch Search (user requests several roles at once)\n- Purpose: Return grouped results for multiple titles.\n- Sequence:\n  - Clarify any shared preferences (location, remote).\n  - For each title:\n    - Action: GoogleJobs_SearchJobs\n      - Action Input: {\"query\":\"\u003ctitle\u003e\", \"location\":\"\u003clocation\u003e\", \"language\":\"en\", \"limit\":3, \"next_page_token\":null}\n  - Present grouped top results per title and ask which ones the user wants to explore further.\n\n6) Iterative Refinement (user asks to narrow by experience, salary, or keywords)\n- Purpose: Re-run searches with refined queries/filters.\n- Sequence:\n  - Ask clarifying follow-up (experience level, salary minimum, seniority, tech stack).\n  - Action: GoogleJobs_SearchJobs\n    - Action Input: {\"query\":\"\u003crefined query\u003e\", \"location\":\"\u003cif any\u003e\", \"language\":\"en\", \"limit\":5, \"next_page_token\":null}\n  - Present refined results and explain which filters matched.\n\nTool Result Processing Rules\n----------------------------\n- Parse each job result and produce a concise \u201cjob card\u201d for the user:\n  - Job Title \u2014 Company \u2014 Location \u2014 Posted \u2014 Salary: \u003cvalue or \"not specified\"\u003e \u2014 Short snippet \u2014 Apply link/source\n- If descriptions are long, show a 1\u20132 sentence summary and offer to show the full text.\n- If results include structured pagination tokens, store the next_page_token only for the current session to fetch more results on user request.\n- If the tool returns ambiguous or zero results:\n  - Tell the user: \u201cNo results found for \u0027\u003cquery\u003e\u0027 in \u0027\u003clocation\u003e\u0027.\u201d\n  - Suggest 2\u20133 adjustments (broaden title, remove location, add \u2018remote\u2019, try related titles).\n\nExample end-to-end conversation (compact)\n-----------------------------------------\nUser: \"Find data analyst jobs in Boston\"\nAgent:\nThought: Need to fetch current openings for \"data analyst\" in Boston.\nAction: GoogleJobs_SearchJobs\nAction Input:\n{\n  \"query\": \"data analyst\",\n  \"location\": \"Boston, MA\",\n  \"language\": \"en\",\n  \"limit\": 5,\n  \"next_page_token\": null\n}\nObservation: [\n  { \"title\":\"Data Analyst\", \"company\":\"Acme Inc\", \"location\":\"Boston, MA\", \"posted\":\"2 days ago\", \"snippet\":\"SQL, Tableau...\", \"apply_link\":\"https://...\"},\n  ...\n]\nFinal Answer: I found 5 data analyst openings in Boston. Top results:\n1) Data Analyst \u2014 Acme Inc \u2014 Boston, MA \u2014 Posted 2 days ago \u2014 SQL, Tableau... \u2014 Apply: https://...\n2) ...\nWould you like more results, or should I filter by experience or salary?\n\nOperational and safety notes\n----------------------------\n- Only present information that appears in tool output. If uncertain, say \u201cnot specified\u201d or \u201cnot provided.\u201d\n- Limit the number of tool calls to what\u2019s necessary. Ask clarifying questions before large batch or multi-query searches.\n- Do not request or store the user\u2019s r\u00e9sum\u00e9 or account passwords. Offer to help draft a tailored resume or cover letter if the user requests, but don\u2019t call the job-search tool for that.\n- If the user requests to apply or to perform actions outside searching (submitting forms, logging into websites), explain you cannot perform those actions but offer step-by-step guidance.\n\nUse this prompt to instantiate the ReAct agent. It will guide the agent to think, call GoogleJobs_SearchJobs correctly, handle pagination and refinements, and present clean, verifiable job information to the user.";
// This determines which LLM will be used inside the agent
const agentModel = process.env.OPENAI_MODEL;
if (!agentModel) {
  throw new Error("Missing OPENAI_MODEL. Add it to your .env file.");
}
// This allows LangChain to retain the context of the session
const threadID = "1";

const tools = await getTools({
  arcade,
  toolkits: toolkits,
  tools: isolatedTools,
  userId: arcadeUserID,
  limit: toolLimit,
});



async function handleInterrupt(
  interrupt: Interrupt,
  rl: readline.Interface
): Promise<{ authorized: boolean }> {
  const value = interrupt.value;
  const authorization_required = value.authorization_required;
  const hitl_required = value.hitl_required;
  if (authorization_required) {
    const tool_name = value.tool_name;
    const authorization_response = value.authorization_response;
    console.log("‚öôÔ∏è: Authorization required for tool call", tool_name);
    console.log(
      "‚öôÔ∏è: Please authorize in your browser",
      authorization_response.url
    );
    console.log("‚öôÔ∏è: Waiting for you to complete authorization...");
    try {
      await arcade.auth.waitForCompletion(authorization_response.id);
      console.log("‚öôÔ∏è: Authorization granted. Resuming execution...");
      return { authorized: true };
    } catch (error) {
      console.error("‚öôÔ∏è: Error waiting for authorization to complete:", error);
      return { authorized: false };
    }
  } else if (hitl_required) {
    console.log("‚öôÔ∏è: Human in the loop required for tool call", value.tool_name);
    console.log("‚öôÔ∏è: Please approve the tool call", value.input);
    const approved = await confirm("Do you approve this tool call?", rl);
    return { authorized: approved };
  }
  return { authorized: false };
}

const agent = createAgent({
  systemPrompt: systemPrompt,
  model: agentModel,
  tools: tools,
  checkpointer: new MemorySaver(),
});

async function streamAgent(
  agent: any,
  input: any,
  config: any
): Promise<Interrupt[]> {
  const stream = await agent.stream(input, {
    ...config,
    streamMode: "updates",
  });
  const interrupts: Interrupt[] = [];

  for await (const chunk of stream) {
    if (chunk.__interrupt__) {
      interrupts.push(...(chunk.__interrupt__ as Interrupt[]));
      continue;
    }
    for (const update of Object.values(chunk)) {
      for (const msg of (update as any)?.messages ?? []) {
        console.log("ü§ñ: ", msg.toFormattedString());
      }
    }
  }

  return interrupts;
}

async function main() {
  const config = { configurable: { thread_id: threadID } };
  const rl = readline.createInterface({
    input: process.stdin,
    output: process.stdout,
  });

  console.log(chalk.green("Welcome to the chatbot! Type 'exit' to quit."));
  while (true) {
    const input = await rl.question("> ");
    if (input.toLowerCase() === "exit") {
      break;
    }
    rl.pause();

    try {
      let agentInput: any = {
        messages: [{ role: "user", content: input }],
      };

      // Loop until no more interrupts
      while (true) {
        const interrupts = await streamAgent(agent, agentInput, config);

        if (interrupts.length === 0) {
          break; // No more interrupts, we're done
        }

        // Handle all interrupts
        const decisions: any[] = [];
        for (const interrupt of interrupts) {
          decisions.push(await handleInterrupt(interrupt, rl));
        }

        // Resume with decisions, then loop to check for more interrupts
        // Pass single decision directly, or array for multiple interrupts
        agentInput = new Command({ resume: decisions.length === 1 ? decisions[0] : decisions });
      }
    } catch (error) {
      console.error(error);
    }

    rl.resume();
  }
  console.log(chalk.red("üëã Bye..."));
  process.exit(0);
}

// Run the main function
main().catch((err) => console.error(err));